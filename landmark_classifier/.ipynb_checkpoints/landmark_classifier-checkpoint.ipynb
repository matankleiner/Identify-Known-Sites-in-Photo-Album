{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre trained YOLO model as a landmark classifier  \n",
    "\n",
    "As we mentioned in the test.ipynb notebook (in the data directory), the test set we use is full of out of domain images. We would like to discard as many of them as possible. In order to do that we will use an object detector and further processing to create our own landmark classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO\n",
    "\n",
    "We will use [YOLO](https://pjreddie.com/darknet/yolo/) (You Only Look Once) pre trained model as an object detctor. YOLO is a state of the art object detctor that achived great results on various data sets. We used [darknet](https://github.com/AlexeyAB/darknet) implemntation which allow to use pre-trained models easily. \n",
    "\n",
    "After cloning the darknet repo, we changed the Makefile in order it to use the GPU and preform faster (as described in the [readme](\"https://github.com/AlexeyAB/darknet/blob/master/README.md\") file). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Images Dataset\n",
    "\n",
    "We chose to use the YOLOv3 that was pre trained on the [Open Images Dataset](\"https://storage.googleapis.com/openimages/web/index.html\"). Open Images dataset is a big, diverse data set with ~9M images annotated with image-level labels, object bounding boxes, object segmentation masks, visual relationships, and localized narratives. We used it's detection part that contain 15,851,536 boxes on 600 categories. The bounding box annotation made by people and not by computers and therefore are higly accurate.  \n",
    "\n",
    "Out of the 600 categories we chose 5 categroies that could indicate that the image contain a landmark: Tower, Fountain, Skyscraper, Building and Castle.  \n",
    "\n",
    "Another 8 categories could inidicate that the image may contain a landmark Bronze sculpture, Sculpture, Lighthouse, House, Tree, Palm tree, Watercraft, Hiking equipment. \n",
    "\n",
    "All the other classes can indicate that it is not a landmark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples: \n",
    "\n",
    "##### Landmarks: \n",
    "\n",
    "<img src=\"example_images/openimages_landmark_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/openimages_landmark_2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "##### Maybe landmarks: \n",
    "\n",
    "<img src=\"example_images/openimages_maybe_landmark_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/openimages_maybe_landmark_2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "##### Non-landmarks: \n",
    "\n",
    "<img src=\"example_images/openimages_non_landmark_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/openimages_non_landmark_2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obejct detection results\n",
    "\n",
    "We passed all the test set images inside the yolo-darknet implementation. The network produced a json file as a result. In this file each image is connected to its filename and the objects that detected in it. For each detected object there will be the corresponding class_id, name and the realtive coordinates, \n",
    "\n",
    "Some examples of the network result (on test set images) as images with bounding box: \n",
    "\n",
    "<img src=\"example_images/predictions1.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/predictions2.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/predictions3.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/predictions9.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The results may not be perfect but they are good and the best that we can achive with that method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Dataset\n",
    "\n",
    "In addition to YOLOv3 that was pre traine on Open Images Dataset, we also used YOLOv4 that was pre trained on the [COCO Dataset](\"https://cocodataset.org/#home\"). In the COCO Dataset there are no classes that we can label as landmark, therefore we'll use those detection to discard more out of domain images from our test set.  \n",
    "\n",
    "#### Obejct detection results\n",
    "\n",
    "Some examples of the network (that was pre-trained on COCO Dataset) result (on test set images) as images with bounding box: \n",
    "\n",
    "<img src=\"example_images/predictions_v4_1.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/predictions_v4_2.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<img src=\"example_images/predictions_v4_3.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "As we can see from the results, the network can detect quite well objects in the scene but cannot detect any kind of landmark. \n",
    "Therefore, as we mentioned before, we'll use the results from this network to discard more images. \n",
    "\n",
    "We will further process the results file in oreder to clean the test set as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further processing\n",
    "\n",
    "We will further process the results file in oreder to clean the test set as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for code \n",
    "import json\n",
    "import pandas as pd \n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pars_results(path):\n",
    "    \"\"\"\n",
    "    Load the results file from the yolo v3 object detector and pars thh results file so\n",
    "    every image will be connected to its filename and objects that detected in it.\n",
    "    for each object that was detected there will be the corresponding class name, confidence level \n",
    "    and size (realtive to the image)  \n",
    "    Param:\n",
    "        path (string): The path to the results file \n",
    "    Return: \n",
    "        data (list): A list of dictionaries. Each element is a dictionary of an image after parsing.  \n",
    "    \"\"\"\n",
    "    f = open(path)  \n",
    "    data = json.load(f) \n",
    " \n",
    "    for i in range(len(data)): \n",
    "        file_name = re.search('[a-z & 0-9]{16}', data[i]['filename']).group(0)\n",
    "        data[i]['filename'] = file_name\n",
    "        if len(data[i]['objects']) != 0: \n",
    "            for j in range(len(data[i]['objects'])): \n",
    "                data[i]['objects'][j].pop('class_id', None)\n",
    "                new_key1 = \"class_name\"\n",
    "                old_key1 = \"name\"\n",
    "                data[i]['objects'][j][new_key1] = data[i]['objects'][j].pop(old_key1)\n",
    "                relative_size = data[i]['objects'][j]['relative_coordinates']['width'] *\\\n",
    "                                data[i]['objects'][j]['relative_coordinates']['height']\n",
    "                data[i]['objects'][j].pop('relative_coordinates', None)\n",
    "                data[i]['objects'][j]['realtive_size'] = relative_size\n",
    "                new_key2 = \"confidence_val\"\n",
    "                old_key2 = \"confidence\"\n",
    "                data[i]['objects'][j][new_key2] = data[i]['objects'][j].pop(old_key2)                \n",
    "    return data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_results(data):\n",
    "    \"\"\"\n",
    "    Check if the objects that detcted in the test set images can be landmarks \n",
    "    Param:\n",
    "        data (list): The parsed data \n",
    "    Return: \n",
    "        keep_df (DataFrame): A dataframe of the images that were labeled as landmarks \n",
    "        throw_df (DataFrame): A dataframe of the images that were labeled as non-landmarks \n",
    "    \"\"\"\n",
    "    \n",
    "    # list of Open Images Dataset classes that we chose as \"landmark\" or \"maybe_landmark\"\n",
    "    landmark = ['Tower', 'Fountain', 'Skyscraper', 'Building', 'Castle']\n",
    "    maybe_landmark_1 = ['Bronze sculpture', 'Sculpture', 'Lighthouse', 'House']\n",
    "    maybe_landmark_2 = ['Tree', 'Palm tree', 'Watercraft', 'Hiking equipment']\n",
    "    \n",
    "    keep = []\n",
    "    throw = []\n",
    "    for i in range(len(data)): \n",
    "        if len(data[i]['objects']) != 0: \n",
    "            for j in range(len(data[i]['objects'])): \n",
    "                # if any of the dtected objects can be defined as one of the landmark list we'll keep it   \n",
    "                if data[i]['objects'][j]['class_name'] in landmark: \n",
    "                    keep.append(data[i])\n",
    "                # if any of the detected objects can be defined as one of the maybe_landmark lists we will check its \n",
    "                # confidence value and realtive size.\n",
    "                # for classes in maybe_landmarks_1 list we'll use large threshold,\n",
    "                # because those classes are of big objects.\n",
    "                # for classes in maybe_landmarks_2 list we'll use small threshold,\n",
    "                # because those classes are of small objects.  \n",
    "                elif data[i]['objects'][j]['class_name'] in maybe_landmark_1:\n",
    "                    if data[i]['objects'][j]['confidence_val'] > 0.5 and data[i]['objects'][j]['realtive_size'] > 0.6:\n",
    "                        keep.append(data[i])\n",
    "                elif data[i]['objects'][j]['class_name'] in maybe_landmark_2:\n",
    "                    if data[i]['objects'][j]['confidence_val'] > 0.5 and data[i]['objects'][j]['realtive_size'] < 0.2:\n",
    "                        keep.append(data[i])\n",
    "                # if the objects detected cannot be defined as landmark or maybe_landmark we will check its confidence value \n",
    "                # and its realtive size (to make sure its the major part of the image) to make sure we want to throw it as \n",
    "                # this image is not a landmark. \n",
    "                else: \n",
    "                    if data[i]['objects'][j]['confidence_val'] > 0.3 and data[i]['objects'][j]['realtive_size'] > 0.6: \n",
    "                        throw.append(data[i])\n",
    "                        \n",
    "    # remove duplicates rows\n",
    "    keep_df_tmp = pd.DataFrame(keep)\n",
    "    keep_df = keep_df_tmp.drop_duplicates(subset=['frame_id'])\n",
    "    keep_df = keep_df.reset_index()\n",
    "    keep_df = keep_df.drop('index', axis=1)\n",
    "    \n",
    "    throw_df_tmp = pd.DataFrame(throw)\n",
    "    throw_df = throw_df_tmp.drop_duplicates(subset=['frame_id'])\n",
    "    throw_df = throw_df.reset_index()\n",
    "    throw_df = throw_df.drop('index', axis=1)\n",
    "\n",
    "    # remove from \"throw\" rows that are also in \"keep\"\n",
    "    if (keep_df.empty): # in case we use YOLOv4 data \"keep\" is empty\n",
    "        return keep_df, throw_df \n",
    "    else: \n",
    "        keep_series = keep_df['frame_id']\n",
    "        throw_df = throw_df[~throw_df[\"frame_id\"].isin(keep_series)]\n",
    "        throw_df = throw_df.reset_index()\n",
    "        throw_df = throw_df.drop('index', axis=1)\n",
    "\n",
    "    return keep_df, throw_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using YOLOv3 object detection on all the available test set images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using YOLO object detection and post processing, our object detector found 12659 images that can be labeled as landmark and 24543 images that can be labeled as non-landmark.\n",
      "\n",
      "The original size of the test set is 117227. After removing from it all the images that where labled as non-landmarkits size is 92706.\n",
      "\n",
      "The original size of the test set without out of domain images is 1622. After removing from it all the images that where    labled as non-landmark its size is 1610. That mean we misclassify 12 images.\n"
     ]
    }
   ],
   "source": [
    "path = 'result_yolov3_openimages.json'\n",
    "data_v3_openimages = pars_results(path)\n",
    "keep_v3_openimage, throw_v3_openimages = processing_results(data_v3_openimages) \n",
    "\n",
    "# save the keep_v3_openimage to dir\n",
    "keep_v3_openimage.to_csv('C:/Users/Matan/Desktop/ProjectB/landmark_classifier/landmarks_csv_files/keep_v3_openimage.csv'\\\n",
    "                         , index = False) \n",
    "print(\"Using YOLO object detection and post processing, our object detector found {} images that can be labeled as\"\n",
    "      \" landmark and {} images that can be labeled as non-landmark.\"\\\n",
    "      .format(keep_v3_openimage.shape[0], throw_v3_openimages.shape[0]))\n",
    "\n",
    "throw_series = throw_v3_openimages['filename'] # all the images in throw_v3_openimages \n",
    "\n",
    "# load test set and remove from it all the images that were labled as non-landmark and therfore are in \"throw_v3_openimages\"\n",
    "test_url = \"https://raw.githubusercontent.com/matankleiner/ProjectB/master/data/test/test.csv\"\n",
    "test_df = pd.read_csv(test_url) \n",
    "clean_test_df = test_df[~test_df[\"id\"].isin(throw_series)]\n",
    "clean_test_df = clean_test_df.reset_index()\n",
    "clean_test_df = clean_test_df.drop('index', axis=1)\n",
    "# save the clean_test_v3 csv to dir\n",
    "clean_test_df.to_csv('C:/Users/Matan/Desktop/projectB/data/test/clean_test_v3.csv', index = False) \n",
    "print(\"\\nThe original size of the test set is {}. After removing from it all the images that where labled as non-landmark\"\n",
    "      \"its size is {}.\".format(test_df.shape[0], clean_test_df.shape[0]))\n",
    "\n",
    "# load the test set without out of domain images\n",
    "test_no_out_of_domain_url =\\\n",
    "            \"https://raw.githubusercontent.com/matankleiner/ProjectB/master/data/test/test_no_out_of_domain.csv\"\n",
    "test_no_out_of_domain_df = pd.read_csv(test_no_out_of_domain_url) \n",
    "clean_test_no_out_of_domain_df = test_no_out_of_domain_df[~test_no_out_of_domain_df[\"id\"].isin(throw_series)]\n",
    "clean_test_no_out_of_domain_df = clean_test_no_out_of_domain_df.reset_index()\n",
    "clean_test_no_out_of_domain_df = clean_test_no_out_of_domain_df.drop('index', axis=1)\n",
    "print(\"\\nThe original size of the test set without out of domain images is {}. \"\n",
    "      \"After removing from it all the images that where    labled as non-landmark its size is {}. \"\n",
    "      \"That mean we misclassify {} images.\".format(test_no_out_of_domain_df.shape[0], \\\n",
    "      clean_test_no_out_of_domain_df.shape[0], \\\n",
    "      test_no_out_of_domain_df.shape[0] - clean_test_no_out_of_domain_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine it with YOLOv4 object detection on all the available test set images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'result_yolov4.json'\n",
    "data_v4 = pars_results(path_1)\n",
    "_, throw_v4 = processing_results(data_v4) # using YOLOv4 there are no images to \"keep\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using both YOLOv3 on Open Images Dataset and YOLOv4 on COCO dataset we labeld 31352 iamges as non landmark.\n",
      "\n",
      "The original size of the test set is 117227. After removing from it all the images that where labled as non-landmarkits size is 85910.\n",
      "\n",
      "The original size of the test set without out of domain images is 1622. After removing from it all the images that where    labled as non-landmark its size is 1594. That mean we misclassify 28 images.\n"
     ]
    }
   ],
   "source": [
    "# remove from throw_v4 rows that are also in keep_v3_openimage\n",
    "keep_series = keep_v3_openimage['frame_id']\n",
    "throw_v4 = throw_v4[~throw_v4[\"frame_id\"].isin(keep_series)]\n",
    "throw_v4 = throw_v4.reset_index()\n",
    "throw_v4 = throw_v4.drop('index', axis=1)\n",
    "\n",
    "# combine throw_v4 and throw_v3_openimages to create throw_all dataframe \n",
    "throw_v3_v4 = pd.concat([throw_v3_openimages, throw_v4])\n",
    "throw_v3_v4 = throw_v3_v4.drop_duplicates(subset=['frame_id'])\n",
    "throw_v3_v4 = throw_v3_v4.reset_index()\n",
    "throw_v3_v4 = throw_v3_v4.drop('index', axis=1)\n",
    "\n",
    "print(\"Using both YOLOv3 on Open Images Dataset and YOLOv4 on COCO dataset\"\n",
    "      \" we labeld {} iamges as non landmark.\".format(throw_v3_v4.shape[0]))\n",
    "\n",
    "throw_series_1 = throw_v3_v4['filename'] # all the images in throw_v3_v4 \n",
    "\n",
    "# load test set and remove from it all the images that were labled as non-landmark and therfore\n",
    "# are in \"throw_v3_v4\"\n",
    "test_url = \"https://raw.githubusercontent.com/matankleiner/ProjectB/master/data/test/test.csv\"\n",
    "test_df = pd.read_csv(test_url) \n",
    "clean_test_v3_v4 = test_df[~test_df[\"id\"].isin(throw_series_1)]\n",
    "clean_test_v3_v4 = clean_test_v3_v4.reset_index()\n",
    "clean_test_v3_v4 = clean_test_v3_v4.drop('index', axis=1)\n",
    "# save the clean_test_v3_v4 csv to dir\n",
    "clean_test_v3_v4.to_csv('C:/Users/Matan/Desktop/projectB/data/test/clean_test_v3_v4.csv', index = False) \n",
    "print(\"\\nThe original size of the test set is {}. After removing from it all the images that where labled as non-landmark\"\n",
    "      \"its size is {}.\".format(test_df.shape[0], clean_test_v3_v4.shape[0]))\n",
    "\n",
    "# load the test set without out of domain images\n",
    "test_no_out_of_domain_url =\\\n",
    "            \"https://raw.githubusercontent.com/matankleiner/ProjectB/master/data/test/test_no_out_of_domain.csv\"\n",
    "test_no_out_of_domain_df = pd.read_csv(test_no_out_of_domain_url) \n",
    "clean_test_no_out_of_domain_v3_v4 = test_no_out_of_domain_df[~test_no_out_of_domain_df[\"id\"].isin(throw_series_1)]\n",
    "clean_test_no_out_of_domain_v3_v4 = clean_test_no_out_of_domain_v3_v4.reset_index()\n",
    "clean_test_no_out_of_domain_v3_v4 = clean_test_no_out_of_domain_v3_v4.drop('index', axis=1)\n",
    "print(\"\\nThe original size of the test set without out of domain images is {}. \"\n",
    "      \"After removing from it all the images that where    labled as non-landmark its size is {}. \"\n",
    "      \"That mean we misclassify {} images.\".format(test_no_out_of_domain_df.shape[0], \\\n",
    "      clean_test_no_out_of_domain_v3_v4.shape[0], \\\n",
    "      test_no_out_of_domain_df.shape[0] - clean_test_no_out_of_domain_v3_v4.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We tried different threshold and got the following results (for both YOLOv3 and YOLOv4). \n",
    "\n",
    "We'll use Precision-Recall to check the differnce success of each threshold. \n",
    "\n",
    "Precision ($P$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p)$.\n",
    "\n",
    "$P = \\frac{T_p}{T_p+F_p}$\n",
    "\n",
    "Recall ($R$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$).\n",
    "\n",
    "$R = \\frac{T_p}{T_p+F_n}$\n",
    "\n",
    "In our case:\n",
    "\n",
    "$T_p = $ Discarder Images - Discarded Landmarks + Total # of Landmarks - Discarded Landmarks\n",
    "\n",
    "$F_p = $ Discarded Landmarks\n",
    "\n",
    "$F_n = $ Total # of Images - Discarder Images + Total # of Landmarks - Discarded Landmarks\n",
    "\n",
    "High precision relates to a low false positive rate, high recall relates to a low false negative rate.\n",
    "\n",
    "We'll also use $F1$ which is the harmonic mean of precision and recall: \n",
    "\n",
    "$F1 = 2\\cdot\\frac{P\\cdot R}{P+R}$\n",
    "\n",
    "| ~ |  Discarded Images | Discarded Landmarks | Precision (%) | Recall(%) | F1 |\n",
    "| :---: | :---: | :---: | :---: | :---: | :---: |   \n",
    "| (confidence_val, realtive_size) = (0.3, 0.6) | 31352 | 28 | 99.91 | 27.34 | 0.43 |\n",
    "| (confidence_val, realtive_size) = (0.3, 0.5) | 37584 | 38 | 99.9 | 32.51 | 0.49 |\n",
    "| (confidence_val, realtive_size) = (0.3, 0.4) | 45404 | 59 | 99.87 | 39 | 0.56 |\n",
    "| (confidence_val, realtive_size) = (0.25, 0.4) | 48039 | 68 | 99.86 | 41.18 | 0.58 |\n",
    "| (confidence_val, realtive_size) = (0.25, 0.45) | 43759 | 57 | 99.87 | 37.62 | 0.55 |\n",
    "| (confidence_val, realtive_size) = (0.25, 0.5) | 39784 | 44 | 99.89 | 34.33 | 0.51 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For threshold 0.3,0.6 is (P,R): (99.91501244460632, 27.343483930989226)% and F1 is 0.43\n",
      "For threshold 0.3,0.5 is (P,R): (99.90298202614379, 32.51161128974634)% and F1 is 0.49\n",
      "For threshold 0.3,0.4 is (P,R): (99.87437988374816, 38.99446356426755)% and F1 is 0.56\n",
      "For threshold 0.25,0.4 is (P,R): (99.86288387474038, 41.17920959199115)% and F1 is 0.58\n",
      "For threshold 0.25,0.45 is (P,R): (99.87423881387343, 37.628428927680794)% and F1 is 0.55\n",
      "For threshold 0.25,0.5 is (P,R): (99.89362216527248, 34.33467122046884)% and F1 is 0.51\n",
      "\n",
      "With very loose threshold:\n",
      "For threshold 0.1,0.1 is (P,R): (99.64271883471373, 66.68422328676648)% and F1 is 0.80\n",
      "For threshold 0.01,0.01 is (P,R): (99.43600120549361, 77.69956013086737)% and F1 is 0.87\n",
      "\n",
      "With very strict threshold:\n",
      "For threshold 0.8,0.5 is (P,R): (99.96186763833573, 19.588356414599318)% and F1 is 0.33\n",
      "For threshold 0.9,0.9 is (P,R): (100.0, 8.366328826024521)% and F1 is 0.15\n"
     ]
    }
   ],
   "source": [
    "def PR(discardedLandmarks, discardedImages, NImages=117227, Nlandmarks=1622): \n",
    "    Tp = discardedImages - discardedLandmarks + Nlandmarks - discardedLandmarks\n",
    "    Fp = discardedLandmarks\n",
    "    Fn = NImages - discardedImages + Nlandmarks - discardedLandmarks\n",
    "    R = (Tp/(Tp+Fn))\n",
    "    P = (Tp/(Tp+Fp))\n",
    "    F1 = 2 * (P*R) / (P+R)\n",
    "    return P*100, R*100, F1\n",
    "\n",
    "print(\"For threshold 0.3,0.6 is (P,R): {}% and F1 is {:.2f}\".format(PR(28,31352)[0:2], PR(28,31352)[2]))\n",
    "print(\"For threshold 0.3,0.5 is (P,R): {}% and F1 is {:.2f}\".format(PR(38,37584)[0:2], PR(38,37584)[2]))\n",
    "print(\"For threshold 0.3,0.4 is (P,R): {}% and F1 is {:.2f}\".format(PR(59,45404)[0:2], PR(59,45404)[2]))\n",
    "print(\"For threshold 0.25,0.4 is (P,R): {}% and F1 is {:.2f}\".format(PR(68,48039)[0:2], PR(68,48039)[2]))\n",
    "print(\"For threshold 0.25,0.45 is (P,R): {}% and F1 is {:.2f}\".format(PR(57,43759)[0:2], PR(57,43759)[2]))\n",
    "print(\"For threshold 0.25,0.5 is (P,R): {}% and F1 is {:.2f}\".format(PR(44,39784)[0:2], PR(44,39784)[2]))\n",
    "print(\"\\nWith very loose threshold:\")\n",
    "print(\"For threshold 0.1,0.1 is (P,R): {}% and F1 is {:.2f}\".format(PR(286,78713)[0:2], PR(286,78713)[2]))\n",
    "print(\"For threshold 0.01,0.01 is (P,R): {}% and F1 is {:.2f}\".format(PR(524,91810)[0:2], PR(524,91810)[2]))\n",
    "print(\"\\nWith very strict threshold:\")\n",
    "print(\"For threshold 0.8,0.5 is (P,R): {}% and F1 is {:.2f}\".format(PR(9,21989)[0:2], PR(9,21989)[2]))\n",
    "print(\"For threshold 0.9,0.9 is (P,R): {}% and F1 is {:.2f}\".format(PR(0,8457)[0:2], PR(0,8457)[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
