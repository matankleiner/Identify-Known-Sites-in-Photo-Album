{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for code \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# load the following csv files as dataframe \n",
    "url_train = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/train/train.csv' \n",
    "url_test ='https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/test.csv'\n",
    "url_test_more_classes1 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes1.csv'\n",
    "url_test_more_classes2 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes2.csv'\n",
    "url_test_more_classes3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes3.csv'\n",
    "url_nn_3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/nearest_neighbor_embedded_test_K%3D3_landmarks_only.csv'\n",
    "url_nn_5 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/nearest_neighbor_embedded_test_K%3D5.csv'\n",
    "url_nn_7 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/nearest_neighbor_embedded_test_K%3D7_landmarks_only.csv'\n",
    "\n",
    "train_df = pd.read_csv(url_train)\n",
    "test_df = pd.read_csv(url_test) \n",
    "test_more_classes1_df = pd.read_csv(url_test_more_classes1)\n",
    "test_more_classes2_df = pd.read_csv(url_test_more_classes2)\n",
    "test_more_classes3_df = pd.read_csv(url_test_more_classes3)\n",
    "nn_3_df = pd.read_csv(url_nn_3)\n",
    "nn_5_df = pd.read_csv(url_nn_5)\n",
    "nn_7_df = pd.read_csv(url_nn_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_df(df): \n",
    "    \"\"\"\n",
    "    Changing the dataframe so it will be easier to work with. \n",
    "    Param: \n",
    "        df (pd.DataFrame): The dataframe to change \n",
    "    Return: \n",
    "        df (pd.DataFrame): The chnaged dataframe \n",
    "    \"\"\"\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df.insert(0, \"id\", test_df[\"id\"], True) \n",
    "    return df \n",
    "\n",
    "nn_3_df = change_df(nn_3_df)\n",
    "nn_5_df = change_df(nn_5_df)\n",
    "nn_7_df = change_df(nn_7_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_indx_to_class(nn_df, train_df, K):\n",
    "    \"\"\"\n",
    "    The nn_df hold the index of the matching neighbor in the train set, this function replace it with the matching class \n",
    "    Param: \n",
    "        nn_df (DataFrame): The nearest neighbors dataframe\n",
    "        train_df (DataFrame): The train set dataframe\n",
    "        K (int): The number of nearest neighbors \n",
    "    Return: \n",
    "        nn_df (DataFrame): Thenearest neighbors dataframe, each column k [k is in (0,1,2...K-1)] contain the\n",
    "                           class of the (k+1) nearest neighbor\n",
    "    \"\"\"\n",
    "    for k in range(K): \n",
    "        col_to_replace = train_df.loc[nn_df[str(k)]][\"landmark_id\"]\n",
    "        nn_df[str(k)] = col_to_replace.values\n",
    "    \n",
    "    return nn_df \n",
    "\n",
    "nn_3_df = train_indx_to_class(nn_3_df, train_df, 3)\n",
    "nn_5_df = train_indx_to_class(nn_5_df, train_df, 5)\n",
    "nn_7_df = train_indx_to_class(nn_7_df, train_df, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series of all the indices where there is a landmark \n",
    "landmark_inidices = test_df['landmarks'] != 0 \n",
    "landmark_inidices = landmark_inidices[landmark_inidices].index\n",
    "\n",
    "# create a smaller dataframe of the test set that made out only of the landmarks \n",
    "landmarks_df = test_df.loc[landmark_inidices]\n",
    "landmarks_df = landmarks_df.reset_index()\n",
    "nn_5_df = nn_5_df.reset_index()\n",
    "nn_5_df = nn_5_df.drop(\"index\", axis=1)\n",
    "landmarks_more_classes1_df = test_more_classes1_df.loc[landmark_inidices]\n",
    "landmarks_more_classes1_df = landmarks_more_classes1_df.reset_index()\n",
    "landmarks_more_classes2_df = test_more_classes2_df.loc[landmark_inidices]\n",
    "landmarks_more_classes2_df = landmarks_more_classes2_df.reset_index()\n",
    "landmarks_more_classes3_df = test_more_classes3_df.loc[landmark_inidices]\n",
    "landmarks_more_classes3_df = landmarks_more_classes3_df.reset_index()\n",
    "\n",
    "nn_5_df = nn_5_df.loc[landmark_inidices] \n",
    "nn_5_df = nn_5_df.reset_index()\n",
    "nn_5_df = nn_5_df.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_freq_series_5n_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c86db6ee74d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0msecond_most_freq_serires_3n_4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlandmarks_more_classes3_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"landmarks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnn_3_freq_class_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'second most freq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmost_freq_3_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_freq_series_5n_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmost_freq_series_5n_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                       \u001b[1;33m(\u001b[0m\u001b[0mmost_freq_series_5n_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmost_freq_series_5n_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                       \u001b[1;33m(\u001b[0m\u001b[0mmost_freq_series_5n_3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmost_freq_series_5n_3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'most_freq_series_5n_1' is not defined"
     ]
    }
   ],
   "source": [
    "# create a dataframe of the landmark id, most frequent class and second most frequent class for K=3 neighbors \n",
    "nn_3_df_no_id = nn_3_df.drop(\"id\", axis=1) \n",
    "most_freq3 = []\n",
    "second_most_freq3 = []\n",
    "for i in range (nn_3_df_no_id.shape[0]):\n",
    "    row3 = nn_3_df_no_id.loc[i]\n",
    "    freq_class3 = row3.value_counts()\n",
    "    freq_class3 = pd.DataFrame(freq_class3)\n",
    "    freq_class3 = freq_class3.reset_index()\n",
    "    if freq_class3[i][0] == 1:\n",
    "        most_freq3.append(nn_3_df_no_id[\"0\"][i])\n",
    "        second_most_freq3.append(nn_3_df_no_id[\"1\"][i])\n",
    "    elif freq_class3[i][0] == 3:\n",
    "        most_freq3.append(nn_3_df_no_id[\"0\"][i])\n",
    "        second_most_freq3.append(0)\n",
    "    elif freq_class3[i][0] == 2:\n",
    "        most_freq3.append(freq_class3[\"index\"][0])\n",
    "        second_most_freq3.append(freq_class3[\"index\"][1])\n",
    "        \n",
    "nn_3_freq_class_df = pd.DataFrame(nn_3_df[\"id\"])\n",
    "nn_3_freq_class_df['most freq'] = pd.DataFrame(most_freq3)\n",
    "nn_3_freq_class_df['second most freq'] = pd.DataFrame(second_most_freq3)\n",
    "\n",
    "most_freq_series_3n_1 = landmarks_df[\"landmarks\"] == nn_3_freq_class_df['most freq'] \n",
    "most_freq_series_3n_2 = landmarks_more_classes1_df[\"landmarks\"] == nn_3_freq_class_df['most freq']\n",
    "most_freq_series_3n_3 = landmarks_more_classes2_df[\"landmarks\"] == nn_3_freq_class_df['most freq']\n",
    "most_freq_series_3n_4 = landmarks_more_classes3_df[\"landmarks\"] == nn_3_freq_class_df['most freq']\n",
    " \n",
    "second_most_freq_serires_3n_1 = landmarks_df[\"landmarks\"] == nn_3_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_3n_2 = landmarks_more_classes1_df[\"landmarks\"] == nn_3_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_3n_3 = landmarks_more_classes2_df[\"landmarks\"] == nn_3_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_3n_4 = landmarks_more_classes3_df[\"landmarks\"] == nn_3_freq_class_df['second most freq'] \n",
    "\n",
    "most_freq_3_indices = most_freq_series_5n_1[most_freq_series_5n_1].index.append\\\n",
    "                      (most_freq_series_5n_2[most_freq_series_5n_2].index).append\\\n",
    "                      (most_freq_series_5n_3[most_freq_series_5n_3].index).append\\\n",
    "                      (most_freq_series_5n_4[most_freq_series_5n_4].index)\n",
    "second_most_freq_5_indices = second_most_freq_serires_5n_1[second_most_freq_serires_5n_1].index.append\\\n",
    "                             (second_most_freq_serires_5n_2[second_most_freq_serires_5n_2].index).append\\\n",
    "                             (second_most_freq_serires_5n_3[second_most_freq_serires_5n_3].index).append\\\n",
    "                             (second_most_freq_serires_5n_4[second_most_freq_serires_5n_4].index)\n",
    "predicted5 = len(most_freq_5_indices.append(second_most_freq_5_indices).unique())\n",
    "\n",
    "predicted3 = len(most_freq_series3[most_freq_series3]) + len([second_most_freq_series3[second_most_freq_series3]]) \n",
    "\n",
    "print(\"For K=3 neighbors, the number of landmarks that are part of the most frequent class or the second most frequent\"\n",
    "      \" class is    {}, which is {:.2f}%  accuracy.\".format(predicted3, predicted3/landmarks_df.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the landmark id, most frequent class and second most frequent class for K=5 neighbors \n",
    "nn_5_df_no_id = nn_5_df.drop(\"id\", axis=1) \n",
    "most_freq5 = []\n",
    "second_most_freq5 = []\n",
    "for i in range (nn_5_df_no_id.shape[0]):\n",
    "    row5 = nn_5_df_no_id.loc[i]\n",
    "    freq_class5 = row5.value_counts()\n",
    "    freq_class5 = pd.DataFrame(freq_class5)\n",
    "    freq_class5 = freq_class5.reset_index()\n",
    "    if freq_class5[i][0] == 1:\n",
    "        most_freq5.append(nn_5_df_no_id[\"0\"][i])\n",
    "        second_most_freq5.append(nn_5_df_no_id[\"1\"][i])\n",
    "    elif freq_class5[i][0] == 5:\n",
    "        most_freq5.append(nn_5_df_no_id[\"0\"][i])\n",
    "        second_most_freq5.append(0)\n",
    "    elif freq_class5[i][0] == 4:\n",
    "        most_freq5.append(freq_class5[\"index\"][0])\n",
    "        second_most_freq5.append(freq_class5[\"index\"][1])\n",
    "    elif freq_class5[i][0] == 3:\n",
    "        most_freq5.append(freq_class5[\"index\"][0])\n",
    "        second_most_freq5.append(freq_class5[\"index\"][1])\n",
    "    elif freq_class5[i][0] == 2 and freq_class5[i][1] == 1:\n",
    "        most_freq5.append(freq_class5[\"index\"][0])\n",
    "        for k in range(5):\n",
    "            if nn_5_df_no_id[str(k)][i] != freq_class5[\"index\"][0]:\n",
    "                second_most_freq5.append(nn_5_df_no_id[str(k)][i])\n",
    "    elif freq_class5[i][0] == 2 and freq_class5[i][1] == 2: \n",
    "        most_freq5.append(freq_class5[\"index\"][0])\n",
    "        second_most_freq5.append(freq_class5[\"index\"][1])\n",
    "        \n",
    "nn_5_freq_class_df = pd.DataFrame(nn_5_df[\"id\"])\n",
    "nn_5_freq_class_df['most freq'] = pd.DataFrame(most_freq5)\n",
    "nn_5_freq_class_df['second most freq'] = pd.DataFrame(second_most_freq5)\n",
    "\n",
    "most_freq_series_5n_1 = landmarks_df[\"landmarks\"] == nn_5_freq_class_df['most freq'] \n",
    "most_freq_series_5n_2 = landmarks_more_classes1_df[\"landmarks\"] == nn_5_freq_class_df['most freq']\n",
    "most_freq_series_5n_3 = landmarks_more_classes2_df[\"landmarks\"] == nn_5_freq_class_df['most freq']\n",
    "most_freq_series_5n_4 = landmarks_more_classes3_df[\"landmarks\"] == nn_5_freq_class_df['most freq']\n",
    "\n",
    "second_most_freq_serires_5n_1 = landmarks_df[\"landmarks\"] == nn_5_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_5n_2 = landmarks_more_classes1_df[\"landmarks\"] == nn_5_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_5n_3 = landmarks_more_classes2_df[\"landmarks\"] == nn_5_freq_class_df['second most freq'] \n",
    "second_most_freq_serires_5n_4 = landmarks_more_classes3_df[\"landmarks\"] == nn_5_freq_class_df['second most freq'] \n",
    "\n",
    "most_freq_5_indices = most_freq_series_5n_1[most_freq_series_5n_1].index.append\\\n",
    "                      (most_freq_series_5n_2[most_freq_series_5n_2].index).append\\\n",
    "                      (most_freq_series_5n_3[most_freq_series_5n_3].index).append\\\n",
    "                      (most_freq_series_5n_4[most_freq_series_5n_4].index)\n",
    "second_most_freq_5_indices = second_most_freq_serires_5n_1[second_most_freq_serires_5n_1].index.append\\\n",
    "                             (second_most_freq_serires_5n_2[second_most_freq_serires_5n_2].index).append\\\n",
    "                             (second_most_freq_serires_5n_3[second_most_freq_serires_5n_3].index).append\\\n",
    "                             (second_most_freq_serires_5n_4[second_most_freq_serires_5n_4].index)\n",
    "predicted5 = len(most_freq_5_indices.append(second_most_freq_5_indices).unique())\n",
    "\n",
    "print(\"For K=5 neighbors, the number of landmarks that are part of the most frequent class or the second most frequent\"\n",
    "      \" class is    {}, which is {:.2f}%  accuracy.\".format(predicted5, predicted5/landmarks_df.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr3 = 0\n",
    "for i in range(landmarks_df.shape[0]): \n",
    "    if landmarks_df[\"landmarks\"][i] == nn_3_df[\"0\"][i] or landmarks_df[\"landmarks\"][i] == nn_3_df[\"1\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_3_df[\"2\"][i]:\n",
    "        cntr3 += 1\n",
    "\n",
    "print(\"For K=3 neighbors, the number of landmarks that their class is appeared in at least one of the nearest neighbors\"\n",
    "      \" is {},    which is {:.2f}%  out of all the landamrks.\".format(cntr3, cntr3/landmarks_df.shape[0]*100))\n",
    "\n",
    "cntr5 = 0\n",
    "for i in range(landmarks_df.shape[0]): \n",
    "    if landmarks_df[\"landmarks\"][i] == nn_5_df[\"0\"][i] or landmarks_df[\"landmarks\"][i] == nn_5_df[\"1\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_5_df[\"2\"][i] or landmarks_df[\"landmarks\"][i] == nn_5_df[\"3\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_5_df[\"4\"][i]: \n",
    "        cntr5 += 1\n",
    "\n",
    "print(\"\\nFor K=5 neighbors, the number of landmarks that their class is appeared in at least one of the nearest neighbors\"\n",
    "      \" is {},    which is {:.2f}%  out of all the landamrks.\".format(cntr5, cntr5/landmarks_df.shape[0]*100))\n",
    "\n",
    "cntr7 = 0\n",
    "for i in range(landmarks_df.shape[0]): \n",
    "    if landmarks_df[\"landmarks\"][i] == nn_7_df[\"0\"][i] or landmarks_df[\"landmarks\"][i] == nn_7_df[\"1\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_7_df[\"2\"][i] or landmarks_df[\"landmarks\"][i] == nn_7_df[\"3\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_7_df[\"4\"][i] or landmarks_df[\"landmarks\"][i] == nn_7_df[\"5\"][i] \\\n",
    "       or landmarks_df[\"landmarks\"][i] == nn_7_df[\"6\"][i]: \n",
    "        cntr7 += 1\n",
    "\n",
    "print(\"\\nFor K=7 neighbors, the number of landmarks that their class is appeared in at least one of the nearest neighbors\"\n",
    "      \" is {},    which is {:.2f}%  out of all the landamrks.\".format(cntr7, cntr7/landmarks_df.shape[0]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
