{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "After cleaning our test set with object detection we extracted features from all the data set images (using ResNet18 pre trained model). We used the feture vectors of the data to preform classification using K Nearest Neighbor (K-NN) algorithm. \n",
    "\n",
    "In this notebook we'll process the results from the classification process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for code \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the following csv files as dataframe \n",
    "url_test ='https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/test.csv'\n",
    "url_test_more_classes1 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes1.csv'\n",
    "url_test_more_classes2 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes2.csv'\n",
    "url_test_more_classes3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes3.csv'\n",
    "url_train = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/train/train.csv' \n",
    "url_detctedt_landmarks = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/landmark_classifier/landmarks_csv_files/keep_v3_openimage.csv'\n",
    "url_clean_v3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/clean_test_v3.csv'\n",
    "url_clean_v3_v4 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/clean_test_v3_v4.csv'\n",
    "url_pred = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/predicted_class_embedded_test.csv'\n",
    "url_dist = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/dist_embedded_test.csv' \n",
    "url_nn = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/nearest_neighbor_embedded_test.csv'\n",
    "\n",
    "test_df = pd.read_csv(url_test) \n",
    "test_more_classes1_df = pd.read_csv(url_test_more_classes1)\n",
    "test_more_classes2_df = pd.read_csv(url_test_more_classes2)\n",
    "test_more_classes3_df = pd.read_csv(url_test_more_classes3)\n",
    "train_df = pd.read_csv(url_train)\n",
    "detctedt_landmarks_df = pd.read_csv(url_detctedt_landmarks)\n",
    "clean_v3_df = pd.read_csv(url_clean_v3)\n",
    "clean_v3_v4_df = pd.read_csv(url_clean_v3_v4)\n",
    "pred_df = pd.read_csv(url_pred)\n",
    "dist_df = pd.read_csv(url_dist)\n",
    "nn_df = pd.read_csv(url_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_df(df): \n",
    "    \"\"\"\n",
    "    Changing the dataframe so it will be easier to work with. \n",
    "    Param: \n",
    "        df (pd.DataFrame): The dataframe to change \n",
    "    Return: \n",
    "        df (pd.DataFrame): The chnaged dataframe \n",
    "    \"\"\"\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df.insert(0, \"id\", test_df[\"id\"], True) \n",
    "    return df \n",
    "\n",
    "pred_df = change_df(pred_df)\n",
    "pred_df = pred_df.rename(columns={\"0\": \"prediction\"})\n",
    "dist_df = change_df(dist_df)\n",
    "nn_df = change_df(nn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 275 correct prediction which is 16.95% accuracy out of all the landmarks in the test set.\n",
      "\n",
      "The accuracy out of all the images in the test set is 0.23%\n"
     ]
    }
   ],
   "source": [
    "# due to the way the test set is organized we split it to 4 different test sets  \n",
    "# convert the type of the test_df[\"landmarks\"] from str to np.int64 \n",
    "for i in range(test_df.shape[0]): \n",
    "    np.int64(test_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes1_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes2_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes3_df[\"landmarks\"][i])\n",
    "    \n",
    "# check if any of the given prediction is correct (in each one of the test sets)\n",
    "pred_series1 = test_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series2 = test_more_classes1_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series3 = test_more_classes2_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series4 = test_more_classes3_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "correct_pred = len(pred_series1[pred_series1].index) + len(pred_series2[pred_series2].index) + \\\n",
    "               len(pred_series3[pred_series3].index) + len(pred_series4[pred_series4].index)\n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the test set.\"\\\n",
    "       .format(correct_pred, correct_pred / test_df[test_df.landmarks != 0].shape[0] * 100))\n",
    "print(\"\\nThe accuracy out of all the images in the test set is {:.2f}%\".format(correct_pred / test_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature vectors and K-NN classification we managed to predict **275 landmarks correctly** which is **16.95% accuracy** out of all the landmarks in the test set.\n",
    "\n",
    "However, the test set is mainly out of domain images, so if we calculate our accuracy out of all the images in the test set (i.e, the given test set and the one we cleaned using object detection) it'll be only **0.23%**.\n",
    "\n",
    "We'll calculate the accuracy on the cleaned test set versions. One of them was cleaned using YOLOv3 object detctor and the other was cleaned using YOLOv3 and YOLOv4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 275 correct prediction which is 17.08% accuracy out of all the landmarks in the clean test set using YOLO v3.\n",
      "\n",
      "The accuracy out of all the images in this clean test set is 0.30%\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3 test set \n",
    "pred_clean_v3 = pred_df[pred_df[\"id\"].isin(clean_v3_df[\"id\"])]\n",
    "pred_clean_v3_1 = pred_series1[pred_series1.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_2 = pred_series2[pred_series2.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_3 = pred_series3[pred_series3.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_4 = pred_series4[pred_series4.index.isin(pred_clean_v3.index)]\n",
    "\n",
    "correct_pred_v3 = len(pred_clean_v3_1[pred_clean_v3_1].index) + len(pred_clean_v3_2[pred_clean_v3_2].index) + \\\n",
    "                  len(pred_clean_v3_3[pred_clean_v3_3].index) + len(pred_clean_v3_4[pred_clean_v3_4].index)   \n",
    "                                            \n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the clean test set \"\n",
    "        \"using YOLO v3.\".format(correct_pred_v3, correct_pred_v3/clean_v3_df[clean_v3_df.landmarks != \"0\"].shape[0]*100))\n",
    "print(\"\\nThe accuracy out of all the images in this clean test set is {:.2f}%\"\\\n",
    "      .format(correct_pred_v3 / clean_v3_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 273 correct prediction which is 17.13% accuracy out of all the landmarks in the clean test set using YOLO v3 and\n",
      "YOLO v4.\n",
      "\n",
      "The accuracy out of all the images in this clean test set is 0.32%\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3 test set \n",
    "pred_clean_v3_v4 = pred_df[pred_df[\"id\"].isin(clean_v3_v4_df[\"id\"])]\n",
    "pred_clean_v3_v4 = pred_series[pred_series.index.isin(pred_clean_v3_v4.index)]\n",
    "\n",
    "pred_clean_v3_v4_1 = pred_series1[pred_series1.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_2 = pred_series2[pred_series2.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_3 = pred_series3[pred_series3.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_4 = pred_series4[pred_series4.index.isin(pred_clean_v3_v4.index)]\n",
    "\n",
    "correct_pred_v3_v4 = len(pred_clean_v3_v4_1[pred_clean_v3_v4_1].index)+len(pred_clean_v3_v4_2[pred_clean_v3_v4_2].index)+\\\n",
    "                     len(pred_clean_v3_v4_3[pred_clean_v3_v4_3].index)+len(pred_clean_v3_v4_4[pred_clean_v3_v4_4].index)   \n",
    "\n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the clean test set \"\n",
    "        \"using YOLO v3 and\\nYOLO v4.\".format(correct_pred_v3_v4,\\\n",
    "        correct_pred_v3_v4 / clean_v3_v4_df[clean_v3_v4_df.landmarks != \"0\"].shape[0] * 100))\n",
    "print(\"\\nThe accuracy out of all the images in this clean test set is {:.2f}%\"\\\n",
    "      .format(correct_pred_v3_v4 / clean_v3_v4_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using the clean data set improve the accuracy, out of all the landmarks and out of all the images. However, the improvence is not very significant. \n",
    "\n",
    "The best results we recieved are on the clean test set using YOLO v3 and YOLO v4. In this test set we predicted correctly **273 landmarks** which is which is **17.13% accuracy** out of all the landmarks in this test set and **0.32% accuracy** out of all the images in this test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor examination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the nn_df hold the index of the matching neighbor in the train set, wo would like to replace it with the matching class \n",
    "col_to_replace0 = train_df.loc[nn_df[\"0\"]][\"landmark_id\"]\n",
    "nn_df['0'] = col_to_replace0.values\n",
    "col_to_replace1 = train_df.loc[nn_df[\"1\"]][\"landmark_id\"]\n",
    "nn_df['1'] = col_to_replace1.values\n",
    "col_to_replace2 = train_df.loc[nn_df[\"2\"]][\"landmark_id\"]\n",
    "nn_df['2'] = col_to_replace2.values\n",
    "col_to_replace3 = train_df.loc[nn_df[\"3\"]][\"landmark_id\"]\n",
    "nn_df['3'] = col_to_replace3.values\n",
    "col_to_replace4 = train_df.loc[nn_df[\"4\"]][\"landmark_id\"]\n",
    "nn_df['4'] = col_to_replace4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e324e0f3e6d9e504</td>\n",
       "      <td>42422</td>\n",
       "      <td>79959</td>\n",
       "      <td>138982</td>\n",
       "      <td>93154</td>\n",
       "      <td>147263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9e17c5f3e0c47b3</td>\n",
       "      <td>14968</td>\n",
       "      <td>41941</td>\n",
       "      <td>95885</td>\n",
       "      <td>117418</td>\n",
       "      <td>38746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a748a755ed67512</td>\n",
       "      <td>5156</td>\n",
       "      <td>164193</td>\n",
       "      <td>164193</td>\n",
       "      <td>67109</td>\n",
       "      <td>84309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537bf9bdfccdafea</td>\n",
       "      <td>48328</td>\n",
       "      <td>69301</td>\n",
       "      <td>136675</td>\n",
       "      <td>158991</td>\n",
       "      <td>136675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13f4c974274ee08b</td>\n",
       "      <td>136675</td>\n",
       "      <td>202793</td>\n",
       "      <td>25369</td>\n",
       "      <td>187755</td>\n",
       "      <td>188686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117222</th>\n",
       "      <td>e351c3e672c25fbd</td>\n",
       "      <td>47663</td>\n",
       "      <td>190441</td>\n",
       "      <td>23777</td>\n",
       "      <td>23777</td>\n",
       "      <td>56062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117223</th>\n",
       "      <td>5426472625271a4d</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>113750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117224</th>\n",
       "      <td>7b6a585405978398</td>\n",
       "      <td>171111</td>\n",
       "      <td>112512</td>\n",
       "      <td>200128</td>\n",
       "      <td>21500</td>\n",
       "      <td>142109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117225</th>\n",
       "      <td>d885235ba249cf5d</td>\n",
       "      <td>162403</td>\n",
       "      <td>162403</td>\n",
       "      <td>162403</td>\n",
       "      <td>115930</td>\n",
       "      <td>136675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117226</th>\n",
       "      <td>c7f657e8d0f7fafb</td>\n",
       "      <td>159334</td>\n",
       "      <td>6090</td>\n",
       "      <td>99323</td>\n",
       "      <td>8834</td>\n",
       "      <td>159247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       0       1       2       3       4\n",
       "0       e324e0f3e6d9e504   42422   79959  138982   93154  147263\n",
       "1       d9e17c5f3e0c47b3   14968   41941   95885  117418   38746\n",
       "2       1a748a755ed67512    5156  164193  164193   67109   84309\n",
       "3       537bf9bdfccdafea   48328   69301  136675  158991  136675\n",
       "4       13f4c974274ee08b  136675  202793   25369  187755  188686\n",
       "...                  ...     ...     ...     ...     ...     ...\n",
       "117222  e351c3e672c25fbd   47663  190441   23777   23777   56062\n",
       "117223  5426472625271a4d   54785   54785   54785   54785  113750\n",
       "117224  7b6a585405978398  171111  112512  200128   21500  142109\n",
       "117225  d885235ba249cf5d  162403  162403  162403  115930  136675\n",
       "117226  c7f657e8d0f7fafb  159334    6090   99323    8834  159247\n",
       "\n",
       "[117227 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 139 correct prediction.\n"
     ]
    }
   ],
   "source": [
    "first_neighbor_series = test_df[\"landmarks\"] == nn_df[\"4\"]\n",
    "print (\"There are {} correct prediction.\".format(len(first_neighbor_series[first_neighbor_series].index)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
