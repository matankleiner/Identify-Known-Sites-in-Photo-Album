{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "After cleaning our test set with object detection we extracted features from all the data set images (using ResNet18 pre trained model). We used the feture vectors of the data to preform classification using K Nearest Neighbor (K-NN) algorithm. \n",
    "\n",
    "In this notebook we'll process the results from the classification process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for code \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the following csv files as dataframe \n",
    "url_test ='https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/test.csv'\n",
    "url_test_more_classes1 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes1.csv'\n",
    "url_test_more_classes2 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes2.csv'\n",
    "url_test_more_classes3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/more_classes/test_more_classes3.csv'\n",
    "url_train = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/train/train.csv' \n",
    "url_clean_v3 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/clean_test_v3.csv'\n",
    "url_clean_v3_v4 = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/data/test/clean_test_v3_v4.csv'\n",
    "url_pred = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/predicted_class_embedded_test.csv'\n",
    "url_dist = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/dist_embedded_test.csv' \n",
    "url_nn = 'https://raw.githubusercontent.com/matankleiner/Identify-Known-Sites-in-Photo-Album/master/feature_extraction/results_csv/nearest_neighbor_embedded_test.csv'\n",
    "\n",
    "test_df = pd.read_csv(url_test) \n",
    "test_more_classes1_df = pd.read_csv(url_test_more_classes1)\n",
    "test_more_classes2_df = pd.read_csv(url_test_more_classes2)\n",
    "test_more_classes3_df = pd.read_csv(url_test_more_classes3)\n",
    "train_df = pd.read_csv(url_train)\n",
    "clean_v3_df = pd.read_csv(url_clean_v3)\n",
    "clean_v3_v4_df = pd.read_csv(url_clean_v3_v4)\n",
    "pred_df = pd.read_csv(url_pred)\n",
    "dist_df = pd.read_csv(url_dist)\n",
    "nn_df = pd.read_csv(url_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_df(df): \n",
    "    \"\"\"\n",
    "    Changing the dataframe so it will be easier to work with. \n",
    "    Param: \n",
    "        df (pd.DataFrame): The dataframe to change \n",
    "    Return: \n",
    "        df (pd.DataFrame): The chnaged dataframe \n",
    "    \"\"\"\n",
    "    df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "    df.insert(0, \"id\", test_df[\"id\"], True) \n",
    "    return df \n",
    "\n",
    "pred_df = change_df(pred_df)\n",
    "pred_df = pred_df.rename(columns={\"0\": \"prediction\"})\n",
    "dist_df = change_df(dist_df)\n",
    "nn_df = change_df(nn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 275 correct prediction which is 16.95% accuracy out of all the landmarks in the test set.\n",
      "\n",
      "The accuracy out of all the images in the test set is 0.23%\n"
     ]
    }
   ],
   "source": [
    "# due to the way the test set is organized we split it to 4 different test sets  \n",
    "# convert the type of the test_df[\"landmarks\"] from str to np.int64 \n",
    "for i in range(test_df.shape[0]): \n",
    "    np.int64(test_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes1_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes2_df[\"landmarks\"][i])\n",
    "    np.int64(test_more_classes3_df[\"landmarks\"][i])\n",
    "    \n",
    "# check if any of the given prediction is correct (in each one of the test sets)\n",
    "pred_series1 = test_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series2 = test_more_classes1_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series3 = test_more_classes2_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "pred_series4 = test_more_classes3_df[\"landmarks\"] == pred_df[\"prediction\"]\n",
    "\n",
    "correct_pred = len(pred_series1[pred_series1]) + len(pred_series2[pred_series2]) + \\\n",
    "               len(pred_series3[pred_series3]) + len(pred_series4[pred_series4])\n",
    "\n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the test set.\"\\\n",
    "       .format(correct_pred, correct_pred / test_df[test_df.landmarks != 0].shape[0] * 100))\n",
    "print(\"\\nThe accuracy out of all the images in the test set is {:.2f}%\".format(correct_pred / test_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feature vectors and K-NN classification we managed to predict **275 landmarks correctly** which is **16.95% accuracy** out of all the landmarks in the test set.\n",
    "\n",
    "However, the test set is mainly out of domain images, so if we calculate our accuracy out of all the images in the test set (i.e, the given test set and the one we cleaned using object detection) it'll be only **0.23%**.\n",
    "\n",
    "We'll calculate the accuracy on the cleaned test set versions. One of them was cleaned using YOLOv3 object detctor and the other was cleaned using YOLOv3 and YOLOv4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 275 correct prediction which is 17.08% accuracy out of all the landmarks in the clean test set using YOLO v3.\n",
      "\n",
      "The accuracy out of all the images in this clean test set is 0.30%\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3 test set \n",
    "pred_clean_v3 = pred_df[pred_df[\"id\"].isin(clean_v3_df[\"id\"])]\n",
    "pred_clean_v3_1 = pred_series1[pred_series1.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_2 = pred_series2[pred_series2.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_3 = pred_series3[pred_series3.index.isin(pred_clean_v3.index)]\n",
    "pred_clean_v3_4 = pred_series4[pred_series4.index.isin(pred_clean_v3.index)]\n",
    "\n",
    "correct_pred_v3 = len(pred_clean_v3_1[pred_clean_v3_1]) + len(pred_clean_v3_2[pred_clean_v3_2]) + \\\n",
    "                  len(pred_clean_v3_3[pred_clean_v3_3]) + len(pred_clean_v3_4[pred_clean_v3_4])   \n",
    "                                            \n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the clean test set \"\n",
    "        \"using YOLO v3.\".format(correct_pred_v3, correct_pred_v3/clean_v3_df[clean_v3_df.landmarks != \"0\"].shape[0]*100))\n",
    "print(\"\\nThe accuracy out of all the images in this clean test set is {:.2f}%\"\\\n",
    "      .format(correct_pred_v3 / clean_v3_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 273 correct prediction which is 17.13% accuracy out of all the landmarks in the clean test set using YOLO v3 and\n",
      "YOLO v4.\n",
      "\n",
      "The accuracy out of all the images in this clean test set is 0.32%\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3_v4 test set \n",
    "pred_clean_v3_v4 = pred_df[pred_df[\"id\"].isin(clean_v3_v4_df[\"id\"])]\n",
    "pred_clean_v3_v4_1 = pred_series1[pred_series1.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_2 = pred_series2[pred_series2.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_3 = pred_series3[pred_series3.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_4 = pred_series4[pred_series4.index.isin(pred_clean_v3_v4.index)]\n",
    "\n",
    "correct_pred_v3_v4 = len(pred_clean_v3_v4_1[pred_clean_v3_v4_1]) + len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) +\\\n",
    "                     len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])   \n",
    "\n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the landmarks in the clean test set \"\n",
    "        \"using YOLO v3 and\\nYOLO v4.\".format(correct_pred_v3_v4,\\\n",
    "        correct_pred_v3_v4 / clean_v3_v4_df[clean_v3_v4_df.landmarks != \"0\"].shape[0] * 100))\n",
    "print(\"\\nThe accuracy out of all the images in this clean test set is {:.2f}%\"\\\n",
    "      .format(correct_pred_v3_v4 / clean_v3_v4_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using the clean data set improve the accuracy, out of all the landmarks and out of all the images. However, the improvence is not very significant. \n",
    "\n",
    "The best results we recieved are on the clean test set using YOLO v3 and YOLO v4. In this test set we predicted correctly **273 landmarks** which is which is **17.13% accuracy** out of all the landmarks in this test set and **0.32% accuracy** out of all the images in this test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-ranking\n",
    "\n",
    "We'll do some re-rankning to the given prediction. We'll try to determine what images are out of domain images based on the nearest neighbor information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbor \n",
    "\n",
    "We'll check the class of each neihbor and we'll predict an image as an out of domain if all its neighbors class are different from each other. \n",
    "\n",
    "Since out of domain images are not suppose to look like any of the landmarks we assume that they will have nearest neighbors from different classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e324e0f3e6d9e504</td>\n",
       "      <td>42422</td>\n",
       "      <td>79959</td>\n",
       "      <td>138982</td>\n",
       "      <td>93154</td>\n",
       "      <td>147263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9e17c5f3e0c47b3</td>\n",
       "      <td>14968</td>\n",
       "      <td>41941</td>\n",
       "      <td>95885</td>\n",
       "      <td>117418</td>\n",
       "      <td>38746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a748a755ed67512</td>\n",
       "      <td>5156</td>\n",
       "      <td>164193</td>\n",
       "      <td>164193</td>\n",
       "      <td>67109</td>\n",
       "      <td>84309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537bf9bdfccdafea</td>\n",
       "      <td>48328</td>\n",
       "      <td>69301</td>\n",
       "      <td>136675</td>\n",
       "      <td>158991</td>\n",
       "      <td>136675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13f4c974274ee08b</td>\n",
       "      <td>136675</td>\n",
       "      <td>202793</td>\n",
       "      <td>25369</td>\n",
       "      <td>187755</td>\n",
       "      <td>188686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117222</th>\n",
       "      <td>e351c3e672c25fbd</td>\n",
       "      <td>47663</td>\n",
       "      <td>190441</td>\n",
       "      <td>23777</td>\n",
       "      <td>23777</td>\n",
       "      <td>56062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117223</th>\n",
       "      <td>5426472625271a4d</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>54785</td>\n",
       "      <td>113750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117224</th>\n",
       "      <td>7b6a585405978398</td>\n",
       "      <td>171111</td>\n",
       "      <td>112512</td>\n",
       "      <td>200128</td>\n",
       "      <td>21500</td>\n",
       "      <td>142109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117225</th>\n",
       "      <td>d885235ba249cf5d</td>\n",
       "      <td>162403</td>\n",
       "      <td>162403</td>\n",
       "      <td>162403</td>\n",
       "      <td>115930</td>\n",
       "      <td>136675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117226</th>\n",
       "      <td>c7f657e8d0f7fafb</td>\n",
       "      <td>159334</td>\n",
       "      <td>6090</td>\n",
       "      <td>99323</td>\n",
       "      <td>8834</td>\n",
       "      <td>159247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id       0       1       2       3       4\n",
       "0       e324e0f3e6d9e504   42422   79959  138982   93154  147263\n",
       "1       d9e17c5f3e0c47b3   14968   41941   95885  117418   38746\n",
       "2       1a748a755ed67512    5156  164193  164193   67109   84309\n",
       "3       537bf9bdfccdafea   48328   69301  136675  158991  136675\n",
       "4       13f4c974274ee08b  136675  202793   25369  187755  188686\n",
       "...                  ...     ...     ...     ...     ...     ...\n",
       "117222  e351c3e672c25fbd   47663  190441   23777   23777   56062\n",
       "117223  5426472625271a4d   54785   54785   54785   54785  113750\n",
       "117224  7b6a585405978398  171111  112512  200128   21500  142109\n",
       "117225  d885235ba249cf5d  162403  162403  162403  115930  136675\n",
       "117226  c7f657e8d0f7fafb  159334    6090   99323    8834  159247\n",
       "\n",
       "[117227 rows x 6 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the nn_df hold the index of the matching neighbor in the train set, wo would like to replace it with the matching class \n",
    "col_to_replace0 = train_df.loc[nn_df[\"0\"]][\"landmark_id\"]\n",
    "nn_df['0'] = col_to_replace0.values\n",
    "col_to_replace1 = train_df.loc[nn_df[\"1\"]][\"landmark_id\"]\n",
    "nn_df['1'] = col_to_replace1.values\n",
    "col_to_replace2 = train_df.loc[nn_df[\"2\"]][\"landmark_id\"]\n",
    "nn_df['2'] = col_to_replace2.values\n",
    "col_to_replace3 = train_df.loc[nn_df[\"3\"]][\"landmark_id\"]\n",
    "nn_df['3'] = col_to_replace3.values\n",
    "col_to_replace4 = train_df.loc[nn_df[\"4\"]][\"landmark_id\"]\n",
    "nn_df['4'] = col_to_replace4.values\n",
    "\n",
    "# now, each column k [k is in (0,1,2,3,4)] contain the class of the (k+1) nearest neighbor\n",
    "nn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # disable a flase warning \n",
    "# create a copy of pred_df for re-ranking based on different classes for all neighbors\n",
    "pred_df_re_ranking = pred_df.copy(deep=True) \n",
    "\n",
    "# create a boolean series that indicate if the class in one column is equal to the class in another column for all \n",
    "# columns in the nn_df (0,1,2,3,4) \n",
    "equal01 = nn_df[\"0\"] == nn_df[\"1\"]\n",
    "equal02 = nn_df[\"0\"] == nn_df[\"2\"]\n",
    "equal03 = nn_df[\"0\"] == nn_df[\"3\"]\n",
    "equal04 = nn_df[\"0\"] == nn_df[\"4\"]\n",
    "equal12 = nn_df[\"1\"] == nn_df[\"2\"]\n",
    "equal13 = nn_df[\"1\"] == nn_df[\"3\"]\n",
    "equal14 = nn_df[\"1\"] == nn_df[\"4\"]\n",
    "equal23 = nn_df[\"2\"] == nn_df[\"3\"]\n",
    "equal24 = nn_df[\"2\"] == nn_df[\"4\"]\n",
    "equal34 = nn_df[\"3\"] == nn_df[\"4\"]\n",
    "\n",
    "# if all the classes for an image are different from each other, predict it as an out of domain image with class \"0\". \n",
    "for i in range(pred_df.shape[0]): \n",
    "    if (equal01[i] or equal02[i] or equal03[i] or equal04[i] or equal12[i] or equal13[i] or equal14[i]\\\n",
    "         or equal23[i] or equal24[i] or equal34[i]):\n",
    "        continue \n",
    "    else: \n",
    "        pred_df_re_ranking['prediction'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the re-ranking process we lost 39 correct prediction.\n",
      "\n",
      "There are 236 correct landmark prediction which is 14.55% accuracy out of all the landmarks in the test set.\n",
      "\n",
      "However, now we predicted correctly 63769 images the accuracy out of all the images (landmarks and out of domain) in the    test set is 54.40%\n"
     ]
    }
   ],
   "source": [
    "# in the above process we might lost correct prediction of landmarks, we would like to check it: \n",
    "pred_series_re_reanking = test_df[\"landmarks\"] == pred_df_re_ranking[\"prediction\"]\n",
    "cntr = 0\n",
    "for i in range(pred_series1.shape[0]):\n",
    "    if (pred_series1[i] and pred_series_re_reanking[i]): \n",
    "        cntr = cntr + 1\n",
    "print(\"In the re-ranking process we lost {} correct prediction.\".format(len(pred_series1[pred_series1]) - cntr))\n",
    "\n",
    "# check for the total correct predcition (in each one of the test sets)\n",
    "correct_pred_rr = len(pred_series_re_reanking[pred_series_re_reanking]) + len(pred_series2[pred_series2]) + \\\n",
    "                  len(pred_series3[pred_series3]) + len(pred_series4[pred_series4])\n",
    "landmark_pred = cntr + len(pred_series2[pred_series2]) + len(pred_series3[pred_series3]) + \\\n",
    "                len(pred_series4[pred_series4]) \n",
    "\n",
    "print (\"\\nThere are {} correct landmark prediction which is {:.2f}% accuracy out of all the landmarks in the test set.\"\\\n",
    "       .format(landmark_pred, landmark_pred / test_df[test_df.landmarks != 0].shape[0] * 100))\n",
    "print(\"\\nHowever, now we predicted correctly {} images the accuracy out of all the images (landmarks and out of domain)\"\n",
    "      \" in the    test set is {:.2f}%\".format(correct_pred_rr, correct_pred_rr / test_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, due to the re-ranking process we predicted correctly only **236 landmarks**, which is **14.55% accuracy** out of all the landmark. However we know predicted **63679 images** correctly, which is **54.4% accuracy** out of all the test set. \n",
    "\n",
    "We'll check now our accuracy on the clean_v3_v4 test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51996 correct prediction which is 60.54% accuracy out of all the images in the clean test set using YOLO v3 and\n",
      "YOLO v4.\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3_v4 test set \n",
    "pred_clean_v3_v4_re_ranking = pred_series_re_reanking[pred_series_re_reanking.index.isin(pred_clean_v3_v4.index)]\n",
    "\n",
    "correct_pred_v3_v4_re_ranking = len(pred_clean_v3_v4_re_ranking[pred_clean_v3_v4_re_ranking]) + \\\n",
    "                                len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) + \\\n",
    "                                len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + \\\n",
    "                                len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])   \n",
    "\n",
    "print (\"There are {} correct prediction which is {:.2f}% accuracy out of all the images in the clean test set \"\n",
    "        \"using YOLO v3 and\\nYOLO v4.\".format(correct_pred_v3_v4_re_ranking,\\\n",
    "        correct_pred_v3_v4_re_ranking / clean_v3_v4_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the clean test set we predicted correctly **51996 images** (some of the out of domain images were already discarded from this test set using object detection) which is **60.54%** accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance\n",
    "\n",
    "We'll check the average distance from each test set image to its 5 nearest neighbor. If the distance is greater than some value we'll predict this image as an out of domain image. We'll check it for the values 17, 18, 19, 20. \n",
    "\n",
    "Since out of domain images are not suppose to look like any of the landmarks we assume that the average distance between them to their nearest neighbors will be big.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e324e0f3e6d9e504</td>\n",
       "      <td>17.308729</td>\n",
       "      <td>18.465883</td>\n",
       "      <td>18.467186</td>\n",
       "      <td>18.548554</td>\n",
       "      <td>18.653781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9e17c5f3e0c47b3</td>\n",
       "      <td>15.190139</td>\n",
       "      <td>15.275702</td>\n",
       "      <td>15.514922</td>\n",
       "      <td>15.866928</td>\n",
       "      <td>15.901018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a748a755ed67512</td>\n",
       "      <td>21.093424</td>\n",
       "      <td>21.181752</td>\n",
       "      <td>21.360185</td>\n",
       "      <td>21.501729</td>\n",
       "      <td>21.678210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537bf9bdfccdafea</td>\n",
       "      <td>17.647642</td>\n",
       "      <td>17.882982</td>\n",
       "      <td>17.921077</td>\n",
       "      <td>17.940326</td>\n",
       "      <td>18.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13f4c974274ee08b</td>\n",
       "      <td>15.005162</td>\n",
       "      <td>15.474619</td>\n",
       "      <td>15.555574</td>\n",
       "      <td>15.756343</td>\n",
       "      <td>15.842871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117222</th>\n",
       "      <td>e351c3e672c25fbd</td>\n",
       "      <td>15.190551</td>\n",
       "      <td>15.214958</td>\n",
       "      <td>15.485120</td>\n",
       "      <td>15.553071</td>\n",
       "      <td>15.700142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117223</th>\n",
       "      <td>5426472625271a4d</td>\n",
       "      <td>15.169560</td>\n",
       "      <td>16.422494</td>\n",
       "      <td>17.382131</td>\n",
       "      <td>17.822677</td>\n",
       "      <td>17.833657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117224</th>\n",
       "      <td>7b6a585405978398</td>\n",
       "      <td>11.895901</td>\n",
       "      <td>11.969579</td>\n",
       "      <td>12.129470</td>\n",
       "      <td>12.282135</td>\n",
       "      <td>12.533825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117225</th>\n",
       "      <td>d885235ba249cf5d</td>\n",
       "      <td>16.592096</td>\n",
       "      <td>16.824498</td>\n",
       "      <td>17.247619</td>\n",
       "      <td>17.345342</td>\n",
       "      <td>17.474634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117226</th>\n",
       "      <td>c7f657e8d0f7fafb</td>\n",
       "      <td>14.579601</td>\n",
       "      <td>15.083095</td>\n",
       "      <td>15.164195</td>\n",
       "      <td>15.252212</td>\n",
       "      <td>15.370667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id          0          1          2          3  \\\n",
       "0       e324e0f3e6d9e504  17.308729  18.465883  18.467186  18.548554   \n",
       "1       d9e17c5f3e0c47b3  15.190139  15.275702  15.514922  15.866928   \n",
       "2       1a748a755ed67512  21.093424  21.181752  21.360185  21.501729   \n",
       "3       537bf9bdfccdafea  17.647642  17.882982  17.921077  17.940326   \n",
       "4       13f4c974274ee08b  15.005162  15.474619  15.555574  15.756343   \n",
       "...                  ...        ...        ...        ...        ...   \n",
       "117222  e351c3e672c25fbd  15.190551  15.214958  15.485120  15.553071   \n",
       "117223  5426472625271a4d  15.169560  16.422494  17.382131  17.822677   \n",
       "117224  7b6a585405978398  11.895901  11.969579  12.129470  12.282135   \n",
       "117225  d885235ba249cf5d  16.592096  16.824498  17.247619  17.345342   \n",
       "117226  c7f657e8d0f7fafb  14.579601  15.083095  15.164195  15.252212   \n",
       "\n",
       "                4  \n",
       "0       18.653781  \n",
       "1       15.901018  \n",
       "2       21.678210  \n",
       "3       18.001732  \n",
       "4       15.842871  \n",
       "...           ...  \n",
       "117222  15.700142  \n",
       "117223  17.833657  \n",
       "117224  12.533825  \n",
       "117225  17.474634  \n",
       "117226  15.370667  \n",
       "\n",
       "[117227 rows x 6 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_gt_17 = (dist_df[\"0\"] + dist_df[\"1\"] + dist_df[\"2\"] + dist_df[\"3\"] + dist_df[\"4\"]) / 5 > 17\n",
    "avg_dist_gt_18 = (dist_df[\"0\"] + dist_df[\"1\"] + dist_df[\"2\"] + dist_df[\"3\"] + dist_df[\"4\"]) / 5 > 18\n",
    "avg_dist_gt_19 = (dist_df[\"0\"] + dist_df[\"1\"] + dist_df[\"2\"] + dist_df[\"3\"] + dist_df[\"4\"]) / 5 > 19\n",
    "avg_dist_gt_20 = (dist_df[\"0\"] + dist_df[\"1\"] + dist_df[\"2\"] + dist_df[\"3\"] + dist_df[\"4\"]) / 5 > 20\n",
    "\n",
    "pd.options.mode.chained_assignment = None # disable a flase warning \n",
    "# create a copy of pred_df_re_ranking for further re_ranking based on avg dist from neighbors\n",
    "pred_df_rr_dist_17 = pred_df_re_ranking.copy(deep=True) \n",
    "pred_df_rr_dist_18 = pred_df_re_ranking.copy(deep=True) \n",
    "pred_df_rr_dist_19 = pred_df_re_ranking.copy(deep=True) \n",
    "pred_df_rr_dist_20 = pred_df_re_ranking.copy(deep=True) \n",
    "\n",
    "# if all the classes for an image are different from each other, predict it as an out of domain image with class \"0\". \n",
    "for i in range(pred_df.shape[0]): \n",
    "    if avg_dist_gt_17[i]:\n",
    "        pred_df_rr_dist_17['prediction'][i] = 0\n",
    "    if avg_dist_gt_18[i]:\n",
    "        pred_df_rr_dist_18['prediction'][i] = 0\n",
    "    if avg_dist_gt_19[i]:\n",
    "        pred_df_rr_dist_19['prediction'][i] = 0\n",
    "    if avg_dist_gt_20[i]:\n",
    "        pred_df_rr_dist_20['prediction'][i] = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the re-ranking process we lost 50, 46, 41, 39 correct prediction for average neighbor distance that is greater than 17, 18, 19, 20 accordingly.\n",
      "\n",
      "There are 225, 229, 234, 236 correct landmark which is 13.87%, 14.12%, 14.43%, 14.55% accuracy out of all the landmarks in  the test set for average neighbor distance that is greater than 17, 18, 19, 20 accordingly.\n",
      "\n",
      "However, now we predicted correctly 83914, 76636, 71037, 67408 images and the accuracy out of all the images (landmarks and out of domain) in the test is 71.58%, 65.37%, 60.60%, 57.50% for average neighbor distance that is greater than 17, 18, 19, 20 accordingly.\n"
     ]
    }
   ],
   "source": [
    "# in the above process we might lost correct prediction of landmarks, we would like to check it: \n",
    "pred_series_rr_dist_17 = test_df[\"landmarks\"] == pred_df_rr_dist_17[\"prediction\"]\n",
    "pred_series_rr_dist_18 = test_df[\"landmarks\"] == pred_df_rr_dist_18[\"prediction\"]\n",
    "pred_series_rr_dist_19 = test_df[\"landmarks\"] == pred_df_rr_dist_19[\"prediction\"]\n",
    "pred_series_rr_dist_20 = test_df[\"landmarks\"] == pred_df_rr_dist_20[\"prediction\"]\n",
    "\n",
    "cntr_dist_17 = 0\n",
    "cntr_dist_18 = 0\n",
    "cntr_dist_19 = 0\n",
    "cntr_dist_20 = 0\n",
    "for i in range(pred_series1.shape[0]):\n",
    "    if (pred_series1[i] and pred_series_rr_dist_17[i]): \n",
    "        cntr_dist_17 = cntr_dist_17 + 1\n",
    "    if (pred_series1[i] and pred_series_rr_dist_18[i]): \n",
    "        cntr_dist_18 = cntr_dist_18 + 1\n",
    "    if (pred_series1[i] and pred_series_rr_dist_19[i]): \n",
    "        cntr_dist_19 = cntr_dist_19 + 1\n",
    "    if (pred_series1[i] and pred_series_rr_dist_20[i]): \n",
    "        cntr_dist_20 = cntr_dist_20 + 1\n",
    "print(\"In the re-ranking process we lost {}, {}, {}, {} correct prediction for average neighbor distance\"\n",
    "      \" that is greater than 17, 18, 19, 20 accordingly.\"\\\n",
    "      .format(len(pred_series1[pred_series1]) - cntr_dist_17, len(pred_series1[pred_series1]) - cntr_dist_18,\\\n",
    "              len(pred_series1[pred_series1]) - cntr_dist_19, len(pred_series1[pred_series1]) - cntr_dist_20))\n",
    "\n",
    "# check for the total correct predcition (in each one of the test sets)\n",
    "correct_pred_dist_17 = len(pred_series_rr_dist_17[pred_series_rr_dist_17]) + len(pred_series2[pred_series2]) + \\\n",
    "                    len(pred_series3[pred_series3].index) + len(pred_series4[pred_series4])\n",
    "landmark_pred_dist_17 = cntr_dist_17 + len(pred_series2[pred_series2]) + len(pred_series3[pred_series3]) + \\\n",
    "                     len(pred_series4[pred_series4]) \n",
    "correct_pred_dist_18 = len(pred_series_rr_dist_18[pred_series_rr_dist_18]) + len(pred_series2[pred_series2]) + \\\n",
    "                    len(pred_series3[pred_series3].index) + len(pred_series4[pred_series4])\n",
    "landmark_pred_dist_18 = cntr_dist_18 + len(pred_series2[pred_series2]) + len(pred_series3[pred_series3]) + \\\n",
    "                     len(pred_series4[pred_series4])\n",
    "correct_pred_dist_19 = len(pred_series_rr_dist_19[pred_series_rr_dist_19]) + len(pred_series2[pred_series2]) + \\\n",
    "                    len(pred_series3[pred_series3].index) + len(pred_series4[pred_series4])\n",
    "landmark_pred_dist_19 = cntr_dist_19 + len(pred_series2[pred_series2]) + len(pred_series3[pred_series3]) + \\\n",
    "                     len(pred_series4[pred_series4])\n",
    "correct_pred_dist_20 = len(pred_series_rr_dist_20[pred_series_rr_dist_20]) + len(pred_series2[pred_series2]) + \\\n",
    "                    len(pred_series3[pred_series3].index) + len(pred_series4[pred_series4])\n",
    "landmark_pred_dist_20 = cntr_dist_20 + len(pred_series2[pred_series2]) + len(pred_series3[pred_series3]) + \\\n",
    "                     len(pred_series4[pred_series4])\n",
    "\n",
    "print(\"\\nThere are {}, {}, {}, {} correct landmark which is {:.2f}%, {:.2f}%, {:.2f}%, {:.2f}%\"\n",
    "      \" accuracy out of all the landmarks in  the test set for average neighbor distance that is greater than\"\n",
    "      \" 17, 18, 19, 20 accordingly.\"\\\n",
    "     .format(landmark_pred_dist_17, landmark_pred_dist_18, landmark_pred_dist_19, landmark_pred_dist_20,\n",
    "             landmark_pred_dist_17 / test_df[test_df.landmarks != 0].shape[0] * 100,\\\n",
    "             landmark_pred_dist_18 / test_df[test_df.landmarks != 0].shape[0] * 100,\\\n",
    "             landmark_pred_dist_19 / test_df[test_df.landmarks != 0].shape[0] * 100,\\\n",
    "             landmark_pred_dist_20 / test_df[test_df.landmarks != 0].shape[0] * 100))\n",
    "\n",
    "print(\"\\nHowever, now we predicted correctly {}, {}, {}, {} images and the accuracy out of all the images (landmarks and out of\"\n",
    "      \" domain) in the test is {:.2f}%, {:.2f}%, {:.2f}%, {:.2f}% for average neighbor distance that is greater than\"\n",
    "      \" 17, 18, 19, 20 accordingly.\"\\\n",
    "      .format(correct_pred_dist_17, correct_pred_dist_18, correct_pred_dist_19, correct_pred_dist_20, \n",
    "              correct_pred_dist_17 / test_df.shape[0] * 100, correct_pred_dist_18 / test_df.shape[0] * 100, \n",
    "             correct_pred_dist_19 / test_df.shape[0] * 100, correct_pred_dist_20 / test_df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64696, 60120, 56512, 54222 correct prediction which is 75.33%, 70.00%, 65.80%, 63.13% accuracy out of all the     images in the clean test set using YOLO v3 and YOLO v4 for average neighbor distance that is greater than 17, 18, 19, 20    accordingly.\n"
     ]
    }
   ],
   "source": [
    "# check for the correct prediction in the clean_v3_v4 test set \n",
    "pred_clean_v3_v4_rr_dist_17 = pred_series_rr_dist_17[pred_series_rr_dist_17.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_rr_dist_18 = pred_series_rr_dist_18[pred_series_rr_dist_18.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_rr_dist_19 = pred_series_rr_dist_19[pred_series_rr_dist_19.index.isin(pred_clean_v3_v4.index)]\n",
    "pred_clean_v3_v4_rr_dist_20 = pred_series_rr_dist_20[pred_series_rr_dist_20.index.isin(pred_clean_v3_v4.index)]\n",
    "\n",
    "\n",
    "correct_pred_v3_v4_rr_dist_17 = len(pred_clean_v3_v4_rr_dist_17[pred_clean_v3_v4_rr_dist_17]) + \\\n",
    "                                len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) + \\\n",
    "                                len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + \\\n",
    "                                len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])\n",
    "correct_pred_v3_v4_rr_dist_18 = len(pred_clean_v3_v4_rr_dist_18[pred_clean_v3_v4_rr_dist_18]) + \\\n",
    "                                len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) + \\\n",
    "                                len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + \\\n",
    "                                len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])   \n",
    "correct_pred_v3_v4_rr_dist_19 = len(pred_clean_v3_v4_rr_dist_19[pred_clean_v3_v4_rr_dist_19]) + \\\n",
    "                                len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) + \\\n",
    "                                len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + \\\n",
    "                                len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])   \n",
    "correct_pred_v3_v4_rr_dist_20 = len(pred_clean_v3_v4_rr_dist_20[pred_clean_v3_v4_rr_dist_20]) + \\\n",
    "                                len(pred_clean_v3_v4_2[pred_clean_v3_v4_2]) + \\\n",
    "                                len(pred_clean_v3_v4_3[pred_clean_v3_v4_3]) + \\\n",
    "                                len(pred_clean_v3_v4_4[pred_clean_v3_v4_4])   \n",
    "\n",
    "print (\"There are {}, {}, {}, {} correct prediction which is {:.2f}%, {:.2f}%, {:.2f}%, {:.2f}% accuracy out of\"\n",
    "       \" all the     images in the clean test set using YOLO v3 and YOLO v4 for average neighbor\"\n",
    "       \" distance that is greater than 17, 18, 19, 20    accordingly.\"\\\n",
    "       .format(correct_pred_v3_v4_rr_dist_17, correct_pred_v3_v4_rr_dist_18, correct_pred_v3_v4_rr_dist_19,\\\n",
    "               correct_pred_v3_v4_rr_dist_20, correct_pred_v3_v4_rr_dist_17 / clean_v3_v4_df.shape[0] * 100, \\\n",
    "               correct_pred_v3_v4_rr_dist_18 / clean_v3_v4_df.shape[0] * 100,\\\n",
    "               correct_pred_v3_v4_rr_dist_19 / clean_v3_v4_df.shape[0] * 100,\\\n",
    "               correct_pred_v3_v4_rr_dist_20 / clean_v3_v4_df.shape[0] * 100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "| ~ | Landmarks | Landmarks Acc (%) | Total Images | Total Images Acc (%) |\n",
    "| :---: | :---: | :---: | :---: | :---: |  \n",
    "| Test Set | 275 | 16.95  | 275 | 0.23 |\n",
    "| Clean Test Set YOLO v3 | 275 | 17.08  | 275 | 0.3 |\n",
    "| Clean Test Set YOLO v3 and v4 | 273 | 17.13  | 273 | 0.32 |\n",
    "| Test Set Reranking with NN | 236 | 14.55 | 63769 | 54.4 |\n",
    "| Clean Test Set YOLO v3 and v4 Reranking with NN | - | - | 51996 | 60.54 |\n",
    "| Test Set Reranking with NN and Dist (17) | 225 | 13.87 | 83914 | 71.58 |\n",
    "| Clean Test Set YOLO v3 and v4 Reranking with NN and Dist (17) | - | - | 64696 | 75.33 |\n",
    "| Test Set Reranking with NN and Dist (18) | 229 | 14.12 | 76636 | 65.37 |\n",
    "| Clean Test Set YOLO v3 and v4 Reranking with NN and Dist (18) | - | -  | 60120 | 70 |\n",
    "| Test Set Reranking with NN and Dist (19) | 234 | 14.43 | 67408 | 60.6 |\n",
    "| Clean Test Set YOLO v3 and v4 Reranking with NN and Dist (19) | - | - | 56512 | 65.8 |\n",
    "| Test Set Reranking with NN and Dist (20) | 236 | 14.55| 71037 | 57.5 |\n",
    "| Clean Test Set YOLO v3 and v4 Reranking with NN and Dist (20) | - | - | 54222 | 63.13 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
